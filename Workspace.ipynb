{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CAUTION !!\n",
    "\n",
    "・sequence lengthごとにMinMaxScaleをしているため、全体のグラフをプロットすると不自然な形になっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = {2017: 0, 2018: 1}\n",
    "month = {9: 0, 10: 1, 11: 2, 12: 3, 1: 4, 2: 5}\n",
    "day = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5}\n",
    "time = {9: 0, 10: 1, 11:2, 12: 3, 13: 4, 14: 5, 15: 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor(32, 64, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, :, 5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Embedding(len(year), 20)\n",
    "embedded = m(torch.LongTensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Stock_Loader import load_data\n",
    "from Stock_Preprocessor import process, fast_plot\n",
    "from Stock_RNN import get_model_0\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RELOAD ###\n",
    "\n",
    "import Stock_Preprocessor\n",
    "import Stock_Loader\n",
    "import Stock_RNN\n",
    "\n",
    "reload(Stock_Preprocessor)\n",
    "reload(Stock_RNN)\n",
    "reload(Stock_Loader)\n",
    "\n",
    "from Stock_Loader import load_data\n",
    "from Stock_Preprocessor import process, fast_plot\n",
    "from Stock_RNN import get_model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Import\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Downloading Datasets\n",
      "...Adding Values to Datasets\n"
     ]
    }
   ],
   "source": [
    "df_appl = load_data(\"../Datasets/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day_of_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-11 09:30:00</td>\n",
       "      <td>160.5</td>\n",
       "      <td>160.62</td>\n",
       "      <td>160.5</td>\n",
       "      <td>160.57</td>\n",
       "      <td>407091.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-11 09:31:00</td>\n",
       "      <td>160.58</td>\n",
       "      <td>160.76</td>\n",
       "      <td>160.51</td>\n",
       "      <td>160.51</td>\n",
       "      <td>266236.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-11 09:32:00</td>\n",
       "      <td>160.525</td>\n",
       "      <td>160.53</td>\n",
       "      <td>160.23</td>\n",
       "      <td>160.32</td>\n",
       "      <td>209863.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-11 09:33:00</td>\n",
       "      <td>160.32</td>\n",
       "      <td>160.36</td>\n",
       "      <td>160.03</td>\n",
       "      <td>160.15</td>\n",
       "      <td>205695.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-11 09:34:00</td>\n",
       "      <td>160.15</td>\n",
       "      <td>160.3</td>\n",
       "      <td>160.1001</td>\n",
       "      <td>160.2799</td>\n",
       "      <td>140139.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15595</th>\n",
       "      <td>2017-11-03 15:16:00</td>\n",
       "      <td>172.68</td>\n",
       "      <td>172.7</td>\n",
       "      <td>172.66</td>\n",
       "      <td>172.666</td>\n",
       "      <td>32607</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15596</th>\n",
       "      <td>2017-11-03 15:17:00</td>\n",
       "      <td>172.66</td>\n",
       "      <td>172.69</td>\n",
       "      <td>172.62</td>\n",
       "      <td>172.645</td>\n",
       "      <td>37614</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15597</th>\n",
       "      <td>2017-11-03 15:18:00</td>\n",
       "      <td>172.65</td>\n",
       "      <td>172.65</td>\n",
       "      <td>172.56</td>\n",
       "      <td>172.584</td>\n",
       "      <td>80428</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15598</th>\n",
       "      <td>2017-11-03 15:19:00</td>\n",
       "      <td>172.58</td>\n",
       "      <td>172.583</td>\n",
       "      <td>172.381</td>\n",
       "      <td>172.45</td>\n",
       "      <td>152298</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15599</th>\n",
       "      <td>2017-11-03 15:20:00</td>\n",
       "      <td>172.43</td>\n",
       "      <td>172.6</td>\n",
       "      <td>172.43</td>\n",
       "      <td>172.51</td>\n",
       "      <td>70629</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15600 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TimeStamp     Open     High       Low     Close    Volume  \\\n",
       "0      2017-09-11 09:30:00    160.5   160.62     160.5    160.57  407091.0   \n",
       "1      2017-09-11 09:31:00   160.58   160.76    160.51    160.51  266236.0   \n",
       "2      2017-09-11 09:32:00  160.525   160.53    160.23    160.32  209863.0   \n",
       "3      2017-09-11 09:33:00   160.32   160.36    160.03    160.15  205695.0   \n",
       "4      2017-09-11 09:34:00   160.15    160.3  160.1001  160.2799  140139.0   \n",
       "...                    ...      ...      ...       ...       ...       ...   \n",
       "15595  2017-11-03 15:16:00   172.68    172.7    172.66   172.666     32607   \n",
       "15596  2017-11-03 15:17:00   172.66   172.69    172.62   172.645     37614   \n",
       "15597  2017-11-03 15:18:00   172.65   172.65    172.56   172.584     80428   \n",
       "15598  2017-11-03 15:19:00   172.58  172.583   172.381    172.45    152298   \n",
       "15599  2017-11-03 15:20:00   172.43    172.6    172.43    172.51     70629   \n",
       "\n",
       "       Year  Month  Day  Hour  Day_of_Week  \n",
       "0      2017      9   11     9            0  \n",
       "1      2017      9   11     9            0  \n",
       "2      2017      9   11     9            0  \n",
       "3      2017      9   11     9            0  \n",
       "4      2017      9   11     9            0  \n",
       "...     ...    ...  ...   ...          ...  \n",
       "15595  2017     11    3    15            4  \n",
       "15596  2017     11    3    15            4  \n",
       "15597  2017     11    3    15            4  \n",
       "15598  2017     11    3    15            4  \n",
       "15599  2017     11    3    15            4  \n",
       "\n",
       "[15600 rows x 11 columns]"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### DOWNLOADED #######\n",
    "\n",
    "df_appl.head(15600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...186 row(s) dropped\n",
      "...Transforming Datasets\n",
      "...Cleaning Datasets\n",
      "...Done !\n"
     ]
    }
   ],
   "source": [
    "seq_length = 120\n",
    "feature = [\"Close\", \"Open\", \"High\", \"Low\"]\n",
    "val_length = 600\n",
    "test_length = 600\n",
    "feature_range=(-1,1)\n",
    "\n",
    "train, train_label, val, val_label, test, test_label, meta, scaler =\\\n",
    "                                            process(df_appl, feature, feature_range, seq_length, val_length, test_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42364</th>\n",
       "      <td>2018-02-14 16:00:00</td>\n",
       "      <td>167.32</td>\n",
       "      <td>167.45</td>\n",
       "      <td>167.3</td>\n",
       "      <td>167.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42365</th>\n",
       "      <td>2018-02-15 09:30:00</td>\n",
       "      <td>169.79</td>\n",
       "      <td>169.86</td>\n",
       "      <td>169.36</td>\n",
       "      <td>169.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TimeStamp    Open    High     Low   Close\n",
       "42364  2018-02-14 16:00:00  167.32  167.45   167.3  167.37\n",
       "42365  2018-02-15 09:30:00  169.79  169.86  169.36  169.84"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_appl.iloc[42364:42366, 0:5] # 2018-02-15 -> apple revenue hit all time hight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.970443</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.945595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.769163</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.852258</td>\n",
       "      <td>-0.945595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.614103</td>\n",
       "      <td>-0.759324</td>\n",
       "      <td>-0.677419</td>\n",
       "      <td>-0.711403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.929837</td>\n",
       "      <td>-0.618578</td>\n",
       "      <td>-0.677419</td>\n",
       "      <td>-0.837507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.493071</td>\n",
       "      <td>-0.952850</td>\n",
       "      <td>-0.580645</td>\n",
       "      <td>-0.869933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0 -1.000000 -0.970443 -1.000000 -0.945595\n",
       "1 -0.769163 -1.000000 -0.852258 -0.945595\n",
       "2 -0.614103 -0.759324 -0.677419 -0.711403\n",
       "3 -0.929837 -0.618578 -0.677419 -0.837507\n",
       "4 -0.493071 -0.952850 -0.580645 -0.869933"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check = pd.DataFrame(train[0])\n",
    "df_check.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172.500000</td>\n",
       "      <td>172.518025</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>172.533179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.640776</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>172.590100</td>\n",
       "      <td>172.533179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172.735339</td>\n",
       "      <td>172.646776</td>\n",
       "      <td>172.696726</td>\n",
       "      <td>172.676001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172.542789</td>\n",
       "      <td>172.732610</td>\n",
       "      <td>172.696726</td>\n",
       "      <td>172.599097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172.809150</td>\n",
       "      <td>172.528754</td>\n",
       "      <td>172.755744</td>\n",
       "      <td>172.579321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3\n",
       "0  172.500000  172.518025  172.500000  172.533179\n",
       "1  172.640776  172.500000  172.590100  172.533179\n",
       "2  172.735339  172.646776  172.696726  172.676001\n",
       "3  172.542789  172.732610  172.696726  172.599097\n",
       "4  172.809150  172.528754  172.755744  172.579321"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_checked = pd.DataFrame(scaler.inverse_transform(train[0]))\n",
    "df_checked.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "output_size = 4\n",
    "hidden_dim = 128\n",
    "n_layers = 2\n",
    "bidirectional = False\n",
    "dropout = 0.1\n",
    "lr = 0.001\n",
    "scheduler_step = [75, 100]\n",
    "gamma = 0.1\n",
    "log_dir= \"stock_directional_loss\"\n",
    "\n",
    "model, optimizer, mse_loss, scheduler, writer = get_model_0(input_size, output_size, hidden_dim, n_layers, bidirectional, dropout,\n",
    "                                                             lr, scheduler_step, gamma, log_dir)\n",
    "\n",
    "total_loss = DirectionalMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 150\n",
    "bt_size = 64\n",
    "acc = math.inf\n",
    "\n",
    "best_acc = math.inf\n",
    "best_model = model\n",
    "loss_accumulated = []\n",
    "sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Processing 14401th sample out of 41640 training set. Loss: 7827.628876980954\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 6766.863643065789\n",
      "Epoch: 0 Loss: 6345.291\n",
      "...Evaluation Mode\n",
      "Validation: 1832.879\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 5518.672771883749\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 5465.53082797189\n",
      "Epoch: 1 Loss: 5330.906\n",
      "...Evaluation Mode\n",
      "Validation: 1633.276\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 5279.111118772916\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 5087.132569394196\n",
      "Epoch: 2 Loss: 5026.432\n",
      "...Evaluation Mode\n",
      "Validation: 1482.203\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 4750.279637168994\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 4720.2179344688975\n",
      "Epoch: 3 Loss: 4736.662\n",
      "...Evaluation Mode\n",
      "Validation: 1216.166\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 4421.822334417199\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 4501.208064957891\n",
      "Epoch: 4 Loss: 4490.186\n",
      "...Evaluation Mode\n",
      "Validation: 1202.607\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 4394.115789472002\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 4356.558595736513\n",
      "Epoch: 5 Loss: 4329.284\n",
      "...Evaluation Mode\n",
      "Validation: 1119.158\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 4248.057580264533\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 4225.734380505434\n",
      "Epoch: 6 Loss: 4225.460\n",
      "...Evaluation Mode\n",
      "Validation: 1043.522\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 4027.0146707781646\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 4095.6283235992664\n",
      "Epoch: 7 Loss: 4119.678\n",
      "...Evaluation Mode\n",
      "Validation: 1038.211\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 4091.4602165596675\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 4093.295189153461\n",
      "Epoch: 8 Loss: 4054.753\n",
      "...Evaluation Mode\n",
      "Validation: 991.042\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 4061.6806777837\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 4024.048615453513\n",
      "Epoch: 9 Loss: 3992.348\n",
      "...Evaluation Mode\n",
      "Validation: 977.687\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3992.8836797454715\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3937.6214282905185\n",
      "Epoch: 10 Loss: 3954.523\n",
      "...Evaluation Mode\n",
      "Validation: 954.782\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3980.114906861455\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3883.8481716398655\n",
      "Epoch: 11 Loss: 3910.361\n",
      "...Evaluation Mode\n",
      "Validation: 545.554\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3936.4374926791784\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3823.6344559427903\n",
      "Epoch: 12 Loss: 3864.132\n",
      "...Evaluation Mode\n",
      "Validation: 926.892\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3791.5868833001737\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3807.15840514708\n",
      "Epoch: 13 Loss: 3830.486\n",
      "...Evaluation Mode\n",
      "Validation: 911.446\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3919.9853802215207\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3826.2312810562403\n",
      "Epoch: 14 Loss: 3808.171\n",
      "...Evaluation Mode\n",
      "Validation: 524.081\n",
      "MODEL UPDATED !!\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3743.068220308133\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3798.8328996492332\n",
      "Epoch: 15 Loss: 3779.414\n",
      "...Evaluation Mode\n",
      "Validation: 902.666\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3832.6337694528356\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3789.700357503611\n",
      "Epoch: 16 Loss: 3751.564\n",
      "...Evaluation Mode\n",
      "Validation: 889.935\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3717.374157127553\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3701.6467779808722\n",
      "Epoch: 17 Loss: 3724.975\n",
      "...Evaluation Mode\n",
      "Validation: 905.869\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3693.5096169797193\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3710.6051103536147\n",
      "Epoch: 18 Loss: 3705.239\n",
      "...Evaluation Mode\n",
      "Validation: 894.657\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3627.0769535506192\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3698.0495600240456\n",
      "Epoch: 19 Loss: 3681.666\n",
      "...Evaluation Mode\n",
      "Validation: 894.665\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3772.7723508018307\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3686.056547527699\n",
      "Epoch: 20 Loss: 3672.507\n",
      "...Evaluation Mode\n",
      "Validation: 891.829\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3558.413866511752\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3626.456549040098\n",
      "Epoch: 21 Loss: 3658.042\n",
      "...Evaluation Mode\n",
      "Validation: 872.716\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3696.704269345619\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3697.229293226667\n",
      "Epoch: 22 Loss: 3644.179\n",
      "...Evaluation Mode\n",
      "Validation: 881.460\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3608.6248761389106\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3620.342864033388\n",
      "Epoch: 23 Loss: 3635.431\n",
      "...Evaluation Mode\n",
      "Validation: 872.953\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3676.6965651011046\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3653.3329231115245\n",
      "Epoch: 24 Loss: 3628.529\n",
      "...Evaluation Mode\n",
      "Validation: 884.477\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3584.446864350971\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3620.630645599968\n",
      "Epoch: 25 Loss: 3624.981\n",
      "...Evaluation Mode\n",
      "Validation: 877.366\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3542.5871965038564\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3647.9596651578427\n",
      "Epoch: 26 Loss: 3618.882\n",
      "...Evaluation Mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 848.521\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3622.4964742375687\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3573.8821754731784\n",
      "Epoch: 27 Loss: 3606.168\n",
      "...Evaluation Mode\n",
      "Validation: 864.807\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3570.553827701153\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3546.1223000730747\n",
      "Epoch: 28 Loss: 3601.297\n",
      "...Evaluation Mode\n",
      "Validation: 837.447\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3554.7838117762476\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3547.8156163231233\n",
      "Epoch: 29 Loss: 3589.323\n",
      "...Evaluation Mode\n",
      "Validation: 851.138\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3599.2634433230996\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3624.430266590975\n",
      "Epoch: 30 Loss: 3586.459\n",
      "...Evaluation Mode\n",
      "Validation: 857.396\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3584.770674495834\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3599.1706065585768\n",
      "Epoch: 31 Loss: 3567.739\n",
      "...Evaluation Mode\n",
      "Validation: 835.129\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3468.4462217300866\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3468.6725012578086\n",
      "Epoch: 32 Loss: 3565.523\n",
      "...Evaluation Mode\n",
      "Validation: 846.519\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3616.839483281416\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3527.3407559073685\n",
      "Epoch: 33 Loss: 3552.866\n",
      "...Evaluation Mode\n",
      "Validation: 835.266\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3406.779435916548\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3527.5031682392973\n",
      "Epoch: 34 Loss: 3548.605\n",
      "...Evaluation Mode\n",
      "Validation: 842.709\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3510.4534399192944\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3516.93016578115\n",
      "Epoch: 35 Loss: 3544.187\n",
      "...Evaluation Mode\n",
      "Validation: 835.240\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3521.807102766712\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3544.2914194251903\n",
      "Epoch: 36 Loss: 3537.446\n",
      "...Evaluation Mode\n",
      "Validation: 854.135\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3506.610362040522\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3528.7971899508107\n",
      "Epoch: 37 Loss: 3519.512\n",
      "...Evaluation Mode\n",
      "Validation: 820.522\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3575.4910892749253\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3535.0232527585094\n",
      "Epoch: 38 Loss: 3527.502\n",
      "...Evaluation Mode\n",
      "Validation: 817.624\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3673.435945426468\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3606.447772414087\n",
      "Epoch: 39 Loss: 3513.983\n",
      "...Evaluation Mode\n",
      "Validation: 846.632\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3516.5106276033725\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3504.9616840323165\n",
      "Epoch: 40 Loss: 3519.420\n",
      "...Evaluation Mode\n",
      "Validation: 858.985\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3466.297597088645\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3494.7201543530973\n",
      "Epoch: 41 Loss: 3509.121\n",
      "...Evaluation Mode\n",
      "Validation: 839.689\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3469.5772124470864\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3475.4254811850196\n",
      "Epoch: 42 Loss: 3510.280\n",
      "...Evaluation Mode\n",
      "Validation: 808.848\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3488.4561562037047\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3488.342446624043\n",
      "Epoch: 43 Loss: 3508.231\n",
      "...Evaluation Mode\n",
      "Validation: 823.545\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3435.735958339894\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3450.379279047713\n",
      "Epoch: 44 Loss: 3501.956\n",
      "...Evaluation Mode\n",
      "Validation: 816.305\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3400.5914765319467\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3444.3681122128028\n",
      "Epoch: 45 Loss: 3499.016\n",
      "...Evaluation Mode\n",
      "Validation: 794.571\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3647.3070889447645\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3525.8444240874305\n",
      "Epoch: 46 Loss: 3498.781\n",
      "...Evaluation Mode\n",
      "Validation: 818.713\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3510.6471121574923\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3466.7505669983684\n",
      "Epoch: 47 Loss: 3491.421\n",
      "...Evaluation Mode\n",
      "Validation: 806.907\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3409.740508459838\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3438.9176486501938\n",
      "Epoch: 48 Loss: 3493.642\n",
      "...Evaluation Mode\n",
      "Validation: 817.161\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3434.8591708833665\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3498.040079789653\n",
      "Epoch: 49 Loss: 3492.390\n",
      "...Evaluation Mode\n",
      "Validation: 840.667\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3524.2352008292105\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3523.927321141284\n",
      "Epoch: 50 Loss: 3488.051\n",
      "...Evaluation Mode\n",
      "Validation: 822.115\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3644.391624833894\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3484.1908121320466\n",
      "Epoch: 51 Loss: 3487.758\n",
      "...Evaluation Mode\n",
      "Validation: 818.802\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3544.264869451259\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3508.4439990856167\n",
      "Epoch: 52 Loss: 3484.250\n",
      "...Evaluation Mode\n",
      "Validation: 808.408\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3457.040342180866\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3500.4310128165453\n",
      "Epoch: 53 Loss: 3483.171\n",
      "...Evaluation Mode\n",
      "Validation: 813.704\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3549.6007840651855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Processing 28801th sample out of 41640 training set. Loss: 3497.1668647226365\n",
      "Epoch: 54 Loss: 3484.153\n",
      "...Evaluation Mode\n",
      "Validation: 830.813\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3534.49967698054\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3529.0080731829626\n",
      "Epoch: 55 Loss: 3477.768\n",
      "...Evaluation Mode\n",
      "Validation: 790.600\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3541.1972272316966\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3535.7743774245423\n",
      "Epoch: 56 Loss: 3481.185\n",
      "...Evaluation Mode\n",
      "Validation: 817.689\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3405.8846351979055\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3450.243330732021\n",
      "Epoch: 57 Loss: 3476.970\n",
      "...Evaluation Mode\n",
      "Validation: 818.346\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3542.8313027440972\n",
      "....Processing 28801th sample out of 41640 training set. Loss: 3477.867760028517\n",
      "Epoch: 58 Loss: 3476.210\n",
      "...Evaluation Mode\n",
      "Validation: 811.857\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "....Processing 14401th sample out of 41640 training set. Loss: 3520.3162440618057\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-579-2f9feed47540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mloss_accumulated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        \n",
    "        if phase == \"train\":\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "            for i in range(0, len(train)-1, bt_size):\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                inputs, targets = train[i:i+bt_size, :, :], train_label[i:i+bt_size, :]\n",
    "                \n",
    "                if inputs.shape[0] < bt_size: break\n",
    "                \n",
    "                inputs = torch.from_numpy(inputs).float()\n",
    "                targets = torch.from_numpy(targets).float()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = total_loss(inputs, targets, outputs)\n",
    "                loss_accumulated.append(loss.item()*1000)\n",
    "                \n",
    "                loss.backward(retain_graph=True)\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "                \n",
    "                if (i % 3600 == 0) and (i > bt_size):\n",
    "                    acc = sum(loss_accumulated)*(100) / (len(loss_accumulated))\n",
    "                    print(\"....Processing {}th sample out of {} training set. Loss: {}\".format(i+1,\n",
    "                                                                                             len(train), acc))\n",
    "                    writer.add_scalar(\"Train_Loss\", acc,\n",
    "                                                      (epoch)*(len(train) // 3600) + (i // 3600))\n",
    "                    \n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "            acc = sum(loss_accumulated)*(100) / (len(loss_accumulated))\n",
    "\n",
    "            \n",
    "            print(\"Epoch: {} Loss: {:.3f}\".format(epoch, acc))\n",
    "            \n",
    "            loss_accumulated = []\n",
    "            \n",
    "            perm = np.random.permutation(train.shape[0])\n",
    "            train, train_label = train[perm], train_label[perm]\n",
    "            \n",
    "        elif phase == \"val\":\n",
    "            \n",
    "            print(\"...Evaluation Mode\")\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                for i in range(0, len(val)-1, bt_size):\n",
    "\n",
    "                    inputs, targets = val[i:i+bt_size,:,:], val_label[i:i+bt_size, :]\n",
    "                    \n",
    "                    if inputs.shape[0] < bt_size: break\n",
    "                    \n",
    "                    \n",
    "                    inputs = torch.from_numpy(inputs).float()\n",
    "                    targets = torch.from_numpy(targets).float()\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    loss = loss_func(outputs.view(-1, 4), targets)\n",
    "                    loss_accumulated.append(loss.item()*1000)\n",
    "                \n",
    "                acc = sum(loss_accumulated)*(100) / (len(loss_accumulated))\n",
    "\n",
    "                writer.add_scalar(\"Val_Loss\", acc, epoch)\n",
    "                \n",
    "                print(\"Validation: {:.3f}\".format(acc))\n",
    "                \n",
    "                if acc < best_acc:\n",
    "                    best_model = model\n",
    "                    best_acc = acc\n",
    "                    print(\"MODEL UPDATED !!\")\n",
    "                \n",
    "                loss_accumulated = []\n",
    "                \n",
    "                perm = np.random.permutation(val.shape[0])\n",
    "                val, val_label = val[perm], val_label[perm]\n",
    "                \n",
    "    print(\"-\" * 70)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier(df, column):\n",
    "    idx_list = list()\n",
    "    prev = df[column].iloc[0]\n",
    "    for idx, row in enumerate(df[column]):\n",
    "        if abs(float(row) - float(prev)) > 1:\n",
    "            idx_list.append(idx)\n",
    "        prev = row\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_compare(model, df, df_label, idx_list):\n",
    "    def compare_and_print(df, df_label, idx):\n",
    "            subject = torch.from_numpy(df[idx:idx+1, :, :])\n",
    "            predict = (subject).float()\n",
    "            predicted = model(predict)\n",
    "            target = df_label[idx, :]\n",
    "            previous = df[idx:idx+1, -1, :][0]\n",
    "            print(\"-\"*70)\n",
    "            print(\"idx: {:3}\".format(idx))\n",
    "            print(\"                                   \\t{}\".format(feature))\n",
    "            print()\n",
    "            print(\"Predicted(y_pred)  :\\t{}\".format(predicted.detach().numpy()[0]))\n",
    "            print(\"Target(y^)               :\\t{}\".format(target))\n",
    "            print()\n",
    "            print(\"Last Price(y-1)        :\\t{}\".format(previous))\n",
    "            print()\n",
    "            print(\"(y^ - (y_pred))      => {}\".format((predicted - torch.from_numpy(target).float()).abs().sum()))\n",
    "            print(\"(y^ - (y-1))             => {}\".format((torch.from_numpy(target).float() - torch.from_numpy(previous).float()).abs().sum()))\n",
    "            print(\"-\"*70)\n",
    "    if type(idx_list) == int:\n",
    "        compare_and_print(df, df_label, idx_list)\n",
    "    elif type(idx_list) == list:\n",
    "        for idx in idx_list:\n",
    "            compare_and_print(df, df_label, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "idx:  10\n",
      "                                   \t['Close', 'Open', 'High', 'Low']\n",
      "\n",
      "Predicted(y_pred)  :\t[0.6992865 0.689968  0.6791362 0.688267 ]\n",
      "Target(y^)               :\t[0.88981132 0.78787879 0.83870968 0.83458647]\n",
      "\n",
      "Last Price(y-1)        :\t[0.77358491 0.84848485 0.80645161 0.63909774]\n",
      "\n",
      "(y^ - (y_pred))      => 0.5943285226821899\n",
      "(y^ - (y-1))             => 0.404579222202301\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "idx:  11\n",
      "                                   \t['Close', 'Open', 'High', 'Low']\n",
      "\n",
      "Predicted(y_pred)  :\t[0.8782132  0.89291906 0.88660765 0.89947975]\n",
      "Target(y^)               :\t[0.8490566  0.89393939 0.83870968 0.83458647]\n",
      "\n",
      "Last Price(y-1)        :\t[0.88981132 0.78787879 0.83870968 0.83458647]\n",
      "\n",
      "(y^ - (y_pred))      => 0.14296823740005493\n",
      "(y^ - (y-1))             => 0.14681529998779297\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "idx:  12\n",
      "                                   \t['Close', 'Open', 'High', 'Low']\n",
      "\n",
      "Predicted(y_pred)  :\t[0.7945655  0.7989104  0.7956011  0.80560297]\n",
      "Target(y^)               :\t[0.87924528 0.84848485 0.91935484 0.92481203]\n",
      "\n",
      "Last Price(y-1)        :\t[0.8490566  0.89393939 0.83870968 0.83458647]\n",
      "\n",
      "(y^ - (y_pred))      => 0.37721705436706543\n",
      "(y^ - (y-1))             => 0.2465139627456665\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "idx:  13\n",
      "                                   \t['Close', 'Open', 'High', 'Low']\n",
      "\n",
      "Predicted(y_pred)  :\t[0.88657993 0.89310396 0.87925386 0.8803785 ]\n",
      "Target(y^)               :\t[0.96981132 0.87878788 0.92741935 0.92481203]\n",
      "\n",
      "Last Price(y-1)        :\t[0.87924528 0.84848485 0.91935484 0.92481203]\n",
      "\n",
      "(y^ - (y_pred))      => 0.19014650583267212\n",
      "(y^ - (y-1))             => 0.12893354892730713\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "idx:  14\n",
      "                                   \t['Close', 'Open', 'High', 'Low']\n",
      "\n",
      "Predicted(y_pred)  :\t[0.939894   0.95542645 0.9329027  0.97180295]\n",
      "Target(y^)               :\t[0.83396226 0.96969697 0.96774194 0.86466165]\n",
      "\n",
      "Last Price(y-1)        :\t[0.96981132 0.87878788 0.92741935 0.92481203]\n",
      "\n",
      "(y^ - (y_pred))      => 0.2621828317642212\n",
      "(y^ - (y-1))             => 0.32723110914230347\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "idx:  15\n",
      "                                   \t['Close', 'Open', 'High', 'Low']\n",
      "\n",
      "Predicted(y_pred)  :\t[0.8355025  0.84014344 0.85863054 0.8404078 ]\n",
      "Target(y^)               :\t[0.87924528 0.81818182 0.87096774 0.89473684]\n",
      "\n",
      "Last Price(y-1)        :\t[0.83396226 0.96969697 0.96774194 0.86466165]\n",
      "\n",
      "(y^ - (y_pred))      => 0.13237065076828003\n",
      "(y^ - (y-1))             => 0.32364755868911743\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "idx:  16\n",
      "                                   \t['Close', 'Open', 'High', 'Low']\n",
      "\n",
      "Predicted(y_pred)  :\t[0.8047709 0.8226328 0.8180583 0.8335273]\n",
      "Target(y^)               :\t[0.73856604 0.88636364 0.86290323 0.80451128]\n",
      "\n",
      "Last Price(y-1)        :\t[0.87924528 0.81818182 0.87096774 0.89473684]\n",
      "\n",
      "(y^ - (y_pred))      => 0.20379668474197388\n",
      "(y^ - (y-1))             => 0.3071511387825012\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "idx:  17\n",
      "                                   \t['Close', 'Open', 'High', 'Low']\n",
      "\n",
      "Predicted(y_pred)  :\t[0.7663834  0.77152395 0.7720655  0.7831215 ]\n",
      "Target(y^)               :\t[0.81679389 0.72727273 0.79032258 0.80152672]\n",
      "\n",
      "Last Price(y-1)        :\t[0.73557252 0.88636364 0.86290323 0.80152672]\n",
      "\n",
      "(y^ - (y_pred))      => 0.13132399320602417\n",
      "(y^ - (y-1))             => 0.3128929138183594\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "idx:  18\n",
      "                                   \t['Close', 'Open', 'High', 'Low']\n",
      "\n",
      "Predicted(y_pred)  :\t[0.78136116 0.7809671  0.7982222  0.7941061 ]\n",
      "Target(y^)               :\t[0.84732824 0.81538462 0.9189233  0.89312977]\n",
      "\n",
      "Last Price(y-1)        :\t[0.81679389 0.72307692 0.78920058 0.80152672]\n",
      "\n",
      "(y^ - (y_pred))      => 0.32010936737060547\n",
      "(y^ - (y-1))             => 0.3441677689552307\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "idx:  19\n",
      "                                   \t['Close', 'Open', 'High', 'Low']\n",
      "\n",
      "Predicted(y_pred)  :\t[0.8728189  0.8832207  0.895537   0.89486194]\n",
      "Target(y^)               :\t[0.89312977 0.84615385 0.87838495 0.8778626 ]\n",
      "\n",
      "Last Price(y-1)        :\t[0.84732824 0.81538462 0.9189233  0.89312977]\n",
      "\n",
      "(y^ - (y_pred))      => 0.09152913093566895\n",
      "(y^ - (y-1))             => 0.1323763132095337\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(best_model, test, test_label, [i for i in range(10, 20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectionalMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DirectionalMSELoss, self).__init__()\n",
    "    \n",
    "    def forward(self, inputs, label, outputs, scale=1e-4):\n",
    "\n",
    "        true_dif = inputs[:, -1, :] - label[:, :] \n",
    "        pred_dif = inputs[:, -1, :] - outputs[:, :]\n",
    "        dif_rel = torch.abs(a - b) # 傾きの差 (relative)\n",
    "\n",
    "        #         epsilon = 1e-6\n",
    "        #         dif_abs = (a + epsilon) * (b + epsilon)  傾きのサインの差 if negative then + and - (absolute)\n",
    "\n",
    "        dif_sum = torch.sum(dif_rel)\n",
    "        dif_sum_scaled = dif_sum * scale\n",
    "        \n",
    "        mse =  mse_loss(outputs.view(-1, 4), label)\n",
    "        \n",
    "        return dif_sum_scaled + mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(best_model, \"stock_model_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate baseline (not working)\n",
    "\n",
    "def mse_copy_last_baseline(df, df_label, bt_size, scale=100):\n",
    "    mse = []\n",
    "    for i in range(df.shape[0]):\n",
    "        predicted = df[i][-1]\n",
    "        target = df_label[i]\n",
    "        loss = ((predicted - target) **2).sum()\n",
    "        mse.append(loss)\n",
    "    return scale * (sum(mse) / (len(mse) // bt_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558.2576291834196"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_copy_last_baseline(train, train_label, bt_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "分散された位置からとってきた方がいい（今のままだと連続したところからとってきている）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "###STEP 1 まずEmbeddingなしでClose Priceだけで予測する##\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "############STEP 2 Price4つを加える#############\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "###########STEP 3 Parametersをいじくる###########\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "##########STEP 4 Embeddingsを加える#############\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "###########STEP 6 Loss Functionを変える##########\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "########STEP 5 Transformerを使って予測する#########\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "########STEP 7 Company Embeddingを加える########\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "########STEP 8 Day, Hour, MinuteをMixする##########\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
